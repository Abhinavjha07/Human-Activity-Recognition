{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Action_Recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY_mBsF_ii-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "\n",
        "directory = '/content/ML_Datasets/UCF_11'\n",
        "\n",
        "classes = {\n",
        "    'basketball' : 0,\n",
        "    'biking' : 1,\n",
        "    'diving' : 2,\n",
        "    'golf_swing' : 3,\n",
        "    'horse_riding' : 4,\n",
        "    'soccer_juggling' : 5,\n",
        "    'swing' : 6,\n",
        "    'tennis_swing' : 7,\n",
        "    'trampoline_jumping' : 8,\n",
        "    'volleyball_spiking' : 9,\n",
        "    'walking' : 10\n",
        "    }\n",
        "\n",
        "Y = []\n",
        "X = []\n",
        "for c in os.listdir(directory):\n",
        "    print(c)\n",
        "    if c != 'readme.txt':\n",
        "        label = classes[c]\n",
        "        d = directory + '/'+c\n",
        "        for x in os.listdir(d):\n",
        "            if x != 'Annotation':\n",
        "                z = d+'/'+x\n",
        "                for file in os.listdir(z):\n",
        "                    cap = cv2.VideoCapture(z+'/'+file)\n",
        "                    fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "                    frames = []\n",
        "                    i = 0\n",
        "                    while(cap.isOpened()):\n",
        "                        ret,fr = cap.read()\n",
        "                        if ret!=True:\n",
        "                            break\n",
        "\n",
        "                        fr = cv2.cvtColor(fr,cv2.COLOR_BGR2GRAY)\n",
        "                        fr = cv2.resize(fr,(64,64),interpolation = cv2.INTER_LINEAR)\n",
        "                        fr = fgbg.apply(fr)\n",
        "\n",
        "                        if i%3 == 0:\n",
        "                            frames.append(np.array(fr))\n",
        "\n",
        "                        i += 1\n",
        "                    if len(frames) == 0:\n",
        "                        print(c,x,file)\n",
        "                    if len(frames) != 0:\n",
        "                        X.append(np.array(frames))\n",
        "                        Y.append(np.array(label))\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "train_X = []\n",
        "for i in range(X.shape[0]):\n",
        "    print(X[i].shape)\n",
        "    if X[i].shape[0] < 50:\n",
        "        temp = np.zeros((50,64,64))\n",
        "        temp[0:X[i].shape[0],:,:] = X[i][0]\n",
        "        \n",
        "    else:\n",
        "        temp = X[i][0:50,:,:]\n",
        "\n",
        "    train_X.append(temp)\n",
        "\n",
        "train_X = np.array(train_X)\n",
        "print(train_X.shape)\n",
        "Y = np.reshape(Y,(1652,1))\n",
        "Y = to_categorical(Y)\n",
        "print(Y.shape)\n",
        "\n",
        "\n",
        "np.save('X.npy',train_X)\n",
        "np.save('Y.npy',Y)\n",
        " \n",
        "   \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQo6Lk7yitWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dense,Dropout,Conv3D,Flatten,MaxPooling3D,Input,Add,Reshape\n",
        "import numpy as np\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "n_classes = 11\n",
        "\n",
        "X = np.load('X.npy')\n",
        "Y = np.load('Y.npy')\n",
        "X = np.reshape(X,(-1,50,64,64,1))\n",
        "\n",
        "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
        "train_X = np.concatenate((train_X,test_X))\n",
        "train_Y = np.concatenate((train_Y,test_Y))\n",
        "input_shape = (50,64,64,1)\n",
        "\n",
        "inp = Input(shape=input_shape)\n",
        "encode = Conv3D(64,(3,3,3),activation='relu')(inp)\n",
        "encode = MaxPooling3D((2,2,2),strides = (3,2,2))(encode)\n",
        "print(encode.shape)\n",
        "encode = Dropout(0.4)(encode)\n",
        "encode = Conv3D(128,(5,5,5),activation = 'relu')(encode)\n",
        "print(encode.shape)\n",
        "encode = Conv3D(64,(3,3,3),activation='relu')(encode)\n",
        "encode = Dropout(0.4)(encode)\n",
        "print(encode.shape)\n",
        "encode = Conv3D(128,(5,5,5),activation='relu')(encode)\n",
        "encode = Dropout(0.4)(encode)\n",
        "print(encode.shape)\n",
        "\n",
        "encode = Conv3D(256,(6,6,6),activation = 'relu')(encode)\n",
        "print(encode.shape)\n",
        "\n",
        "encoder = Model(inp,encode)\n",
        "\n",
        "\n",
        "encode = Flatten()(encode)\n",
        "print(encode.shape)\n",
        "\n",
        "\n",
        "x = Dense(128,activation='relu')(encode)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64,activation = 'relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(n_classes,activation= 'softmax')(x)\n",
        "\n",
        "model = Model(inputs = inp,outputs = x)\n",
        "model.summary()\n",
        "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
        "model.fit(train_X,train_Y,epochs = 10,validation_data=(test_X,test_Y))\n",
        "\n",
        "model.save('3DCNN_UCF11')\n",
        "encoding = encoder.predict(X)\n",
        "print(encoding.shape)\n",
        "encoding = np.reshape(encoding,(-1,256,256))\n",
        "encoder.save('encoding')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4_IMCglivDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "encoder = load_model('encoding')\n",
        "X = np.load('X.npy')\n",
        "X = np.reshape(X,(-1,50,64,64,1))\n",
        "encode_X = encoder.predict(X)\n",
        "np.save('encode_X.npy',encode_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2StwvEYliyNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import Dense,Dropout,Conv3D,Flatten,MaxPooling3D,Input,Add,Reshape\n",
        "from keras import initializers\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.models import Model,load_model\n",
        "from keras.engine.topology import Layer\n",
        "import tensorflow as tf\n",
        "\n",
        "n_classes = 11\n",
        "\n",
        "class HierarchicalAttentionNetwork(Layer):\n",
        "    def __init__(self, attention_dim):\n",
        "        self.init = initializers.get('normal')\n",
        "        self.supports_masking = True\n",
        "        self.attention_dim = attention_dim\n",
        "        super(HierarchicalAttentionNetwork, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n",
        "        self.b = K.variable(self.init((self.attention_dim,)))\n",
        "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
        "        self.trainable_weights = [self.W, self.b, self.u]\n",
        "        super(HierarchicalAttentionNetwork, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return mask\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        \n",
        "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
        "\n",
        "        ait = K.exp(K.squeeze(K.dot(uit, self.u), -1))\n",
        "\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting\n",
        "            ait *= K.cast(mask, K.floatx())\n",
        "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        weighted_input = x * K.expand_dims(ait)\n",
        "        output = K.sum(weighted_input, axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "X = np.load('encode_X.npy')\n",
        "Y = np.load('Y.npy')\n",
        "X = np.reshape(X,(-1,256,16*16))\n",
        "\n",
        "\n",
        "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
        "train_X = np.concatenate((train_X,test_X))\n",
        "train_Y = np.concatenate((train_Y,test_Y))\n",
        "input_shape = (256,16*16)\n",
        "\n",
        "\n",
        "\n",
        "inp = Input(shape=input_shape)\n",
        "encode = HierarchicalAttentionNetwork(256)(inp)\n",
        "print(encode.shape)\n",
        "encode = Reshape((16,16))(encode)\n",
        "encode = LSTM(64,return_sequences = True,dropout = 0.2)(encode)\n",
        "encode = LSTM(128,return_sequences = True,dropout = 0.4)(encode)\n",
        "print(encode.shape)\n",
        "encode = HierarchicalAttentionNetwork(128)(encode)\n",
        "print(encode.shape)\n",
        "encode = Reshape((16,8))(encode)\n",
        "encode = LSTM(64,return_sequences = True)(encode)\n",
        "encode = HierarchicalAttentionNetwork(64)(encode)\n",
        "print(encode.shape)\n",
        "\n",
        "x = Dense(128,activation='relu')(encode)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64,activation = 'relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(n_classes,activation= 'softmax')(x)\n",
        "\n",
        "model = Model(inputs = inp,outputs = x)\n",
        "model.summary()\n",
        "model.compile(loss = 'categorical_crossentropy',optimizer = 'rmsprop',metrics = ['accuracy'])\n",
        "model.fit(train_X,train_Y,batch_size = 64,epochs = 20,validation_data=(test_X,test_Y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}